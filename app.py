import streamlit as st  
import pandas as pd  
import numpy as np  
from sklearn.linear_model import LogisticRegression  
from sklearn.ensemble import RandomForestClassifier  
from xgboost import XGBClassifier  

# Configuration de la page  
st.set_page_config(  
    page_title="Pr√©diction de Matchs de Football",  
    page_icon="‚öΩ",  # Ic√¥ne pour le site  
    layout="wide"  
)  

# Fonction pour entra√Æner les mod√®les  
@st.cache_resource  
def train_models():  
    # Cr√©er un ensemble de donn√©es d'entra√Ænement synth√©tique  
    np.random.seed(42)  
    data = pd.DataFrame({  
        'home_goals': np.random.randint(0, 3, size=1000),  
        'away_goals': np.random.randint(0, 3, size=1000),  
        'xG': np.random.uniform(0, 2, size=1000),  
        'xGA': np.random.uniform(0, 2, size=1000),  
        'encais': np.random.uniform(0, 2, size=1000),  
        'face_a_face': np.random.uniform(0, 100, size=1000),  
        'motivation_home': np.random.uniform(0, 100, size=1000),  
        'motivation_away': np.random.uniform(0, 100, size=1000),  
        'victoire_domicile': np.random.uniform(0, 100, size=1000),  
        'victoire_exterieur': np.random.uniform(0, 100, size=1000),  
        'result': np.random.choice([0, 1, 2], size=1000)  
    })  

    # S√©parer les caract√©ristiques et la cible  
    X = data[['home_goals', 'away_goals', 'xG', 'xGA', 'encais', 'face_a_face', 'motivation_home', 'motivation_away', 'victoire_domicile', 'victoire_exterieur']]  
    y = data['result']  

    # Mod√®le de r√©gression logistique avec hyperparam√®tres optimis√©s  
    log_reg = LogisticRegression(max_iter=500, solver='lbfgs')  
    log_reg.fit(X, y)  

    # Mod√®le Random Forest avec hyperparam√®tres optimis√©s  
    rf = RandomForestClassifier(n_estimators=50, max_depth=10, n_jobs=-1)  
    rf.fit(X, y)  

    # Mod√®le XGBoost avec hyperparam√®tres optimis√©s  
    xgb = XGBClassifier(n_estimators=50, max_depth=5, learning_rate=0.3, use_label_encoder=False, eval_metric='logloss', n_jobs=-1)  
    xgb.fit(X, y)  

    return log_reg, rf, xgb  

# V√©rifier si les mod√®les sont d√©j√† charg√©s dans l'√©tat de session  
if 'models' not in st.session_state:  
    st.session_state.models = train_models()  

log_reg_model, rf_model, xgb_model = st.session_state.models  

# Interface utilisateur  
st.title("‚öΩ Pr√©diction de Matchs de Football")  

# S√©lection des √©quipes  
st.subheader("üè† √âquipe Domicile vs üèÉ‚Äç‚ôÇÔ∏è √âquipe Ext√©rieure")  
home_team = st.text_input("Nom de l'√©quipe √† domicile", "√âquipe A")  
away_team = st.text_input("Nom de l'√©quipe √† l'ext√©rieur", "√âquipe B")  

# Pr√©diction des r√©sultats  
if st.button("üîç Pr√©dire les r√©sultats"):  
    # Exemple de pr√©diction avec le mod√®le de r√©gression logistique  
    example_input = np.array([[1, 1, 1.5, 1.2, 0.8, 50, 70, 60, 60, 40]])  # Donn√©es d'exemple  
    log_reg_pred = log_reg_model.predict_proba(example_input)[0]  
    rf_pred = rf_model.predict_proba(example_input)[0]  
    xgb_pred = xgb_model.predict_proba(example_input)[0]  

    # Affichage des r√©sultats  
    st.subheader("üìä R√©sultats de la Pr√©diction")  
    st.write(f"**Probabilit√© de victoire √† domicile ({home_team}) :** {log_reg_pred[2] * 100:.2f}%")  
    st.write(f"**Probabilit√© de match nul :** {log_reg_pred[1] * 100:.2f}%")  
    st.write(f"**Probabilit√© de victoire √† l'ext√©rieur ({away_team}) :** {log_reg_pred[0] * 100:.2f}%")  

    # Comparaison des mod√®les  
    st.subheader("üìà Comparaison des Mod√®les")  
    model_comparison_data = {  
        "Mod√®le": ["R√©gression Logistique", "Random Forest", "XGBoost"],  
        "Probabilit√© Domicile (%)": [log_reg_pred[2] * 100, rf_pred[2] * 100, xgb_pred[2] * 100],  
        "Probabilit√© Nul (%)": [log_reg_pred[1] * 100, rf_pred[1] * 100, xgb_pred[1] * 100],  
        "Probabilit√© Ext√©rieure (%)": [log_reg_pred[0] * 100, rf_pred[0] * 100, xgb_pred[0] * 100],  
    }  
    model_comparison_df = pd.DataFrame(model_comparison_data)  
    st.dataframe(model_comparison_df, use_container_width=True)
    # Affichage des graphiques de comparaison des mod√®les  
st.subheader("üìä Graphiques de Comparaison des Mod√®les")  

# Graphique en barres pour les probabilit√©s de victoire √† domicile  
st.bar_chart(model_comparison_df.set_index("Mod√®le")["Probabilit√© Domicile (%)"])  

# Graphique en barres pour les probabilit√©s de match nul  
st.bar_chart(model_comparison_df.set_index("Mod√®le")["Probabilit√© Nul (%)"])  

# Graphique en barres pour les probabilit√©s de victoire √† l'ext√©rieur  
st.bar_chart(model_comparison_df.set_index("Mod√®le")["Probabilit√© Ext√©rieure (%)"])  

# Section pour afficher les d√©tails des pr√©dictions  
st.subheader("üîç D√©tails des Pr√©dictions")  

# Affichage des probabilit√©s brutes pour chaque mod√®le  
st.write("**Probabilit√©s brutes (R√©gression Logistique) :**", log_reg_pred)  
st.write("**Probabilit√©s brutes (Random Forest) :**", rf_pred)  
st.write("**Probabilit√©s brutes (XGBoost) :**", xgb_pred)  

# Section pour afficher les informations sur les mod√®les  
st.subheader("‚ÑπÔ∏è Informations sur les Mod√®les")  

# Description des mod√®les  
st.write("""  
- **R√©gression Logistique** : Un mod√®le lin√©aire utilis√© pour la classification binaire ou multiclasse.  
- **Random Forest** : Un ensemble d'arbres de d√©cision qui am√©liore la pr√©cision et r√©duit le surapprentissage.  
- **XGBoost** : Un mod√®le de boosting bas√© sur les arbres de d√©cision, connu pour sa performance et sa rapidit√©.  
""")  

# Section pour afficher les donn√©es d'entra√Ænement synth√©tiques  
st.subheader("üìÇ Donn√©es d'Entra√Ænement Synth√©tiques")  

# Affichage des premi√®res lignes des donn√©es synth√©tiques  
st.write("Voici un aper√ßu des donn√©es synth√©tiques utilis√©es pour entra√Æner les mod√®les :")  
st.dataframe(data.head(), use_container_width=True)  

# Section pour afficher les caract√©ristiques utilis√©es pour la pr√©diction  
st.subheader("üîë Caract√©ristiques Utilis√©es pour la Pr√©diction")  

# Liste des caract√©ristiques  
st.write("Les caract√©ristiques suivantes ont √©t√© utilis√©es pour entra√Æner les mod√®les :")  
st.write("""  
- **home_goals** : Nombre de buts marqu√©s par l'√©quipe √† domicile.  
- **away_goals** : Nombre de buts marqu√©s par l'√©quipe √† l'ext√©rieur.  
- **xG** : Expected Goals (xG) de l'√©quipe √† domicile.  
- **xGA** : Expected Goals Against (xGA) de l'√©quipe √† domicile.  
- **encais** : Encaisse des buts de l'√©quipe √† domicile.  
- **face_a_face** : Historique des confrontations entre les deux √©quipes.  
- **motivation_home** : Motivation de l'√©quipe √† domicile.  
- **motivation_away** : Motivation de l'√©quipe √† l'ext√©rieur.  
- **victoire_domicile** : Taux de victoire √† domicile de l'√©quipe √† domicile.  
- **victoire_exterieur** : Taux de victoire √† l'ext√©rieur de l'√©quipe √† l'ext√©rieur.  
""")  

# Section pour afficher les r√©sultats d√©taill√©s  
st.subheader("üìù R√©sultats D√©taill√©s")  

# Affichage des r√©sultats d√©taill√©s pour chaque mod√®le  
st.write("**R√©gression Logistique :**")  
st.write(f"Probabilit√© de victoire √† domicile : {log_reg_pred[2] * 100:.2f}%")  
st.write(f"Probabilit√© de match nul : {log_reg_pred[1] * 100:.2f}%")  
st.write(f"Probabilit√© de victoire √† l'ext√©rieur : {log_reg_pred[0] * 100:.2f}%")  

st.write("**Random Forest :**")  
st.write(f"Probabilit√© de victoire √† domicile : {rf_pred[2] * 100:.2f}%")  
st.write(f"Probabilit√© de match nul : {rf_pred[1] * 100:.2f}%")  
st.write(f"Probabilit√© de victoire √† l'ext√©rieur : {rf_pred[0] * 100:.2f}%")  

st.write("**XGBoost :**")  
st.write(f"Probabilit√© de victoire √† domicile : {xgb_pred[2] * 100:.2f}%")  
st.write(f"Probabilit√© de match nul : {xgb_pred[1] * 100:.2f}%")  
st.write(f"Probabilit√© de victoire √† l'ext√©rieur : {xgb_pred[0] * 100:.2f}%")  

# Section pour afficher les conclusions  
st.subheader("üìå Conclusions")  

# Affichage des conclusions  
st.write("""  
Les r√©sultats montrent que les trois mod√®les donnent des pr√©dictions similaires, mais avec des diff√©rences mineures.   
Le mod√®le **XGBoost** semble √™tre le plus pr√©cis, suivi de pr√®s par le **Random Forest** et la **R√©gression Logistique**.  
""")  

# Section pour afficher les recommandations  
st.subheader("üí° Recommandations")  

# Affichage des recommandations  
st.write("""  
- **Pour des pr√©dictions rapides** : Utilisez la R√©gression Logistique.  
- **Pour des pr√©dictions pr√©cises** : Utilisez XGBoost ou Random Forest.  
- **Pour des donn√©es complexes** : Utilisez XGBoost, car il est plus adapt√© aux donn√©es non lin√©aires.  
""")
# Section pour personnaliser les pr√©dictions  
st.subheader("üéØ Personnaliser les Pr√©dictions")  

# Formulaire pour saisir des valeurs personnalis√©es  
st.write("Entrez les valeurs des caract√©ristiques pour personnaliser la pr√©diction :")  
home_goals_input = st.number_input("Buts √† domicile", min_value=0, value=1)  
away_goals_input = st.number_input("Buts √† l'ext√©rieur", min_value=0, value=1)  
xG_input = st.number_input("Expected Goals (xG) √† domicile", min_value=0.0, value=1.5)  
xGA_input = st.number_input("Expected Goals Against (xGA) √† domicile", min_value=0.0, value=1.2)  
encais_input = st.number_input("Encaisse des buts √† domicile", min_value=
