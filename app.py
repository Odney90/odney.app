import streamlit as st  
import numpy as np  
import pandas as pd  
import matplotlib.pyplot as plt  
from sklearn.model_selection import StratifiedKFold, cross_val_score  
from sklearn.linear_model import LogisticRegression  
from sklearn.ensemble import RandomForestClassifier  
from scipy.stats import poisson  
import traceback  

# Configuration de la page  
st.set_page_config(page_title="âš½ Analyse de Match de Football", page_icon="âš½", layout="wide")  

# Initialisation de st.session_state  
if 'data' not in st.session_state:  
    st.session_state.data = {}  

# Titre de l'application  
st.title("âš½ Analyse de Match de Football")  

# Formulaire de collecte des donnÃ©es  
with st.form("data_form"):  
    st.markdown("### Ã‰quipe A")  
    col1, col2 = st.columns(2)  
    with col1:  
        st.session_state.data['expected_but_A'] = st.number_input("ğŸ“Š Expected Goals (xG)", value=1.5, key="xG_A")  
        st.session_state.data['buts_par_match_A'] = st.number_input("âš½ Buts MarquÃ©s", value=1.5, key="buts_A")  
        st.session_state.data['tirs_cadres_A'] = st.number_input("ğŸ¯ Tirs CadrÃ©s", value=120, key="tirs_A")  
        st.session_state.data['grandes_chances_A'] = st.number_input("ğŸ”¥ Grandes Chances", value=25, key="chances_A")  
        st.session_state.data['corners_A'] = st.number_input("ğŸ”„ Corners", value=60, key="corners_A")  
        st.session_state.data['ratio_tirs_cadres_A'] = st.number_input("ğŸ¯ Ratio Tirs CadrÃ©s", value=0.4, key="ratio_tirs_cadres_A")  

    with col2:  
        st.markdown("### Ã‰quipe B")  
        st.session_state.data['expected_but_B'] = st.number_input("ğŸ“Š Expected Goals (xG)", value=1.2, key="xG_B")  
        st.session_state.data['buts_par_match_B'] = st.number_input("âš½ Buts MarquÃ©s", value=1.0, key="buts_B")  
        st.session_state.data['tirs_cadres_B'] = st.number_input("ğŸ¯ Tirs CadrÃ©s", value=100, key="tirs_B")  
        st.session_state.data['grandes_chances_B'] = st.number_input("ğŸ”¥ Grandes Chances", value=20, key="chances_B")  
        st.session_state.data['corners_B'] = st.number_input("ğŸ”„ Corners", value=50, key="corners_B")  
        st.session_state.data['ratio_tirs_cadres_B'] = st.number_input("ğŸ¯ Ratio Tirs CadrÃ©s", value=0.35, key="ratio_tirs_cadres_B")  

    # Bouton de soumission dans le formulaire  
    submitted = st.form_submit_button("ğŸ” Analyser le Match")  

# Section d'analyse et de prÃ©diction (sÃ©parÃ©e du formulaire)  
if submitted:  
    try:  
        # PrÃ©paration des donnÃ©es pour Poisson  
        lambda_A = (  
            st.session_state.data['expected_but_A']  # xG  
            + st.session_state.data['buts_par_match_A']  # Buts marquÃ©s  
            + st.session_state.data['tirs_cadres_A'] * 0.1  # Tirs cadrÃ©s (pondÃ©ration)  
            + st.session_state.data['grandes_chances_A'] * 0.2  # Grandes chances (pondÃ©ration)  
            + st.session_state.data['corners_A'] * 0.05  # Corners (pondÃ©ration)  
        ) / 3  # Normalisation  

        lambda_B = (  
            st.session_state.data['expected_but_B']  # xG  
            + st.session_state.data['buts_par_match_B']  # Buts marquÃ©s  
            + st.session_state.data['tirs_cadres_B'] * 0.1  # Tirs cadrÃ©s (pondÃ©ration)  
            + st.session_state.data['grandes_chances_B'] * 0.2  # Grandes chances (pondÃ©ration)  
            + st.session_state.data['corners_B'] * 0.05  # Corners (pondÃ©ration)  
        ) / 3  # Normalisation  

        # PrÃ©diction des buts avec Poisson  
        buts_A = poisson.rvs(mu=lambda_A, size=1000)  # 1000 simulations pour l'Ã©quipe A  
        buts_B = poisson.rvs(mu=lambda_B, size=1000)  # 1000 simulations pour l'Ã©quipe B  

        # RÃ©sultats Poisson  
        st.subheader("ğŸ“Š PrÃ©diction des Buts (Poisson)")  
        col_poisson_A, col_poisson_B = st.columns(2)  
        with col_poisson_A:  
            st.metric("âš½ Buts Moyens (Ã‰quipe A)", f"{np.mean(buts_A):.2f}")  
        with col_poisson_B:  
            st.metric("âš½ Buts Moyens (Ã‰quipe B)", f"{np.mean(buts_B):.2f}")  

        # PrÃ©paration des donnÃ©es pour RÃ©gression Logistique et Random Forest  
        X = np.array(list(st.session_state.data.values())).reshape(1, -1)  # Toutes les donnÃ©es des Ã©quipes  
        X = np.repeat(X, 1000, axis=0)  # RÃ©pÃ©ter les donnÃ©es pour correspondre Ã  la taille de y  
        y = np.random.randint(0, 3, 1000)  # 3 classes : 0 (dÃ©faite), 1 (victoire A), 2 (match nul)  

        # ModÃ¨les  
        modeles = {  
            "RÃ©gression Logistique": LogisticRegression(max_iter=1000),  
            "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42)  
        }  

        # Validation croisÃ©e et prÃ©dictions  
        st.markdown("### ğŸ¤– Performance des ModÃ¨les")  
        resultats_modeles = {}  
        for nom, modele in modeles.items():  
            # Validation croisÃ©e stratifiÃ©e  
            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  
            scores = cross_val_score(modele, X, y, cv=cv, scoring='accuracy')  

            # Affichage des mÃ©triques de validation croisÃ©e  
            st.markdown(f"#### {nom}")  
            col_accuracy, col_precision, col_recall, col_f1 = st.columns(4)  
            with col_accuracy:  
                st.metric("ğŸ¯ PrÃ©cision Globale", f"{np.mean(scores):.2%}")  

            # PrÃ©diction finale  
            modele.fit(X, y)  
            proba = modele.predict_proba(X)[0]  

            # Affichage des prÃ©dictions  
            st.markdown("**ğŸ“Š PrÃ©dictions**")  
            col_victoire_A, col_victoire_B, col_nul = st.columns(3)  
            with col_victoire_A:  
                st.metric("ğŸ† Victoire A", f"{proba[1]:.2%}")  
            with col_victoire_B:  
                st.metric("ğŸ† Victoire B", f"{proba[0]:.2%}")  
            with col_nul:  
                st.metric("ğŸ¤ Match Nul", f"{proba[2]:.2%}")  

            # Stockage des rÃ©sultats pour comparaison  
            resultats_modeles[nom] = {  
                'accuracy': np.mean(scores),  
                'precision': np.mean(cross_val_score(modele, X, y, cv=cv, scoring='precision_macro')),  
                'recall': np.mean(cross_val_score(modele, X, y, cv=cv, scoring='recall_macro')),  
                'f1_score': np.mean(cross_val_score(modele, X, y, cv=cv, scoring='f1_macro'))  
            }  

        # Analyse finale  
        probabilite_victoire_A = (  
            (resultats_modeles["RÃ©gression Logistique"]["accuracy"] + resultats_modeles["Random Forest"]["accuracy"]) / 2  
        )  

        st.subheader("ğŸ† RÃ©sultat Final")  
        st.metric("ProbabilitÃ© de Victoire de l'Ã‰quipe A", f"{probabilite_victoire_A:.2%}")  

        # Visualisation des performances des modÃ¨les  
        st.subheader("ğŸ“ˆ Comparaison des Performances des ModÃ¨les")  

        # PrÃ©paration des donnÃ©es pour le graphique  
        metriques = ['accuracy', 'precision', 'recall', 'f1_score']  

        # CrÃ©ation du DataFrame  
        df_performances = pd.DataFrame({  
            nom: [resultats_modeles[nom][metrique] for metrique in metriques]  
            for nom in resultats_modeles.keys()  
        }, index=metriques)  

        # Affichage du DataFrame  
        st.dataframe(df_performances)  

        # Graphique de comparaison  
        fig, ax = plt.subplots(figsize=(10, 6))  
        df_performances.T.plot(kind='bar', ax=ax)  
        plt.title("Comparaison des Performances des ModÃ¨les")  
        plt.xlabel("ModÃ¨les")  
        plt.ylabel("Score")  
        plt.legend(title="MÃ©triques", bbox_to_anchor=(1.05, 1), loc='upper left')  
        plt.tight_layout()  
        st.pyplot(fig)  

    except Exception as e:  
        st.error(f"Erreur lors de la prÃ©diction : {e}")  
        st.error(traceback.format_exc())  

# Pied de page informatif  
st.markdown("""  
### ğŸ¤” Comment InterprÃ©ter ces RÃ©sultats ?  

- **ğŸ“Š PrÃ©diction des Buts (Poisson)** : BasÃ©e sur les Expected Goals (xG) des Ã©quipes.  
- **ğŸ¤– Performance des ModÃ¨les** :   
  - **RÃ©gression Logistique** : ModÃ¨le linÃ©aire simple.  
  - **Random Forest** : ModÃ¨le plus complexe, moins sensible au bruit.  
- **ğŸ“ˆ K-Fold Cross-Validation** : Cette mÃ©thode permet d'Ã©valuer la performance des modÃ¨les en divisant les donnÃ©es en plusieurs sous-ensembles (folds). Chaque fold est utilisÃ© comme ensemble de test, tandis que les autres servent Ã  l'entraÃ®nement. Cela garantit une estimation plus robuste de la performance.  
- **ğŸ† RÃ©sultat Final** : Moyenne pondÃ©rÃ©e des diffÃ©rentes mÃ©thodes de prÃ©diction.  

âš ï¸ *Ces prÃ©dictions sont des estimations statistiques et ne garantissent pas le rÃ©sultat rÃ©el.*  
""")
